{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "c170a559-053c-44f3-8ebf-c580eab173cd",
        "_uuid": "67630004a083cfed0cfec09dc6448a0b0881023f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\npd.options.display.max_rows = 200\n\ntrain_data = pd.read_csv('../input/Train.csv')\ntest_data = pd.read_csv('../input/Test.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0cdaece3-10a5-4144-a32b-f4db205046e3",
        "_uuid": "a9c6460190f13cc57a735e3ef1ae70280bf685bc"
      },
      "cell_type": "markdown",
      "source": "First, let's remove unwanted features (like `id`, `track url`, `name`, etc). "
    },
    {
      "metadata": {
        "_cell_guid": "832b94b7-3810-41c5-a958-d53b08b09ba8",
        "_uuid": "f912469f09486837e5a8fab15c5c5bfb9a419712",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "ignore = (['analysis_url', \n           'id', \n           'track_href', \n           'uri', \n           'type', \n           'album', \n           'name', \n           'duration_ms',\n          ])\n\ntrain_data.drop(ignore, axis=1, inplace=True)\nclean_test_data = test_data.drop(ignore, axis=1)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "38b8ace1-d838-4998-9827-f57ffcf0d03d",
        "_uuid": "c31c2bf4d1d0471483d2be9f83efa947693ef749"
      },
      "cell_type": "markdown",
      "source": "Now, assign classes. The training set is made up of 200 songs. 100 are Steven Wilson songs and the rest are totally different songs. So, the positive class is **1** and the negative class is **0**.\n\nYes, this should totally be in the csv ¯\\\\_(ツ)_/¯ (I'm gonna update it Soon™)."
    },
    {
      "metadata": {
        "_cell_guid": "3faf6dff-6cbc-4ebd-a560-866061be99d0",
        "_uuid": "fc21e8433544476ed92a32a3c630c806408a0b92",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "train_data.loc[:99, 'class'] = [1] * 100\ntrain_data.loc[100:200, 'class'] = [0] * 100",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8459ffbd-f6c5-410e-b7a9-6cbec82f21e1",
        "_uuid": "56236c3c36e91b759460622ef8a9052e030c1eea"
      },
      "cell_type": "markdown",
      "source": "Now, the important part: **which features am I gonna use?** What features define Steven Wilson's style the best?\n  \nAfter trying many combinations, analyzing some [graphs](https://www.kaggle.com/danielgrijalvas/comparing-steven-wilson-and-porcupine-tree) and checking with the Test dataset (a playlist with songs that may or may not sound like SW), I came to the conclusion that the best features for this problem are:\n* Energy\n* Instrumentalness\n* Loudness\n* Acousticness\n* Valence  \n  \nHowever, using some statistical tools like a t-test, we can tell whether the features from class 1 are significantly different from class 2, and select those with higher significance. Using scikit-learn's `feature_selection` and `f_classif` (basically a t-test), the features with higher significance (or \"score\", according to [scikit-learn docs](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)) are:\n* Danceability\n* Instrumentalness\n* Loudness\n* Speechiness\n* Valence  \n  \nSee, I *almost* got it right. `SelectKBest` chose `Danceability` instead of `Energy`, and `Speechiness` instead of `Acousticness`. I understand that the data from `Energy` is very spread out and that's why it got a low score/significance; but `Speechiness`...? That seems weird."
    },
    {
      "metadata": {
        "_cell_guid": "3a2fe40c-c7f7-425a-887b-7410a90d5171",
        "_uuid": "3564707372c1be41d9a2a609a935df65825ef0f3",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.feature_selection import SelectKBest\n\nfeatures = SelectKBest(k=5)\nfeatures.fit(train_data.loc[:, train_data.columns != 'class'], train_data['class'])\n\ncols = list(train_data.columns[features.get_support(1)])\ncols",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "cf5f5bbe-ebb7-4bd3-a4da-761e997bc4fa",
        "_uuid": "f8f746d69197a44b873630822b4e5fee3fbd392b"
      },
      "cell_type": "markdown",
      "source": "Now, let's train the machine learning algorithm, K-Nearest Neighbors. I'm leaving K as the default (5), but maybe later I'll try with higher values.  \n\nAlso, I'm adding some weights with `distance`, that way, the closer neighbors will have *even more* influence over the classifications -- but honestly I don't really know how that works, so I'll probably change that to `uniform` weights."
    },
    {
      "metadata": {
        "_kg_hide-output": true,
        "_cell_guid": "2a39df8d-d235-44a4-90b3-975882210194",
        "_uuid": "f2e4dfe16d21a97686f112e3290c8c1c964acaee",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier as knn\n\n# train KNN with training data \nkn = knn(weights='distance', p=2)\nkn.fit(train_data[cols], train_data['class'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "aa1d7be0-96fc-41ec-a191-d3fdd03a9501",
        "_uuid": "93320b87420981d3203599fe854b1f2762f49f35"
      },
      "cell_type": "markdown",
      "source": "The algorithm is trained. Let's use what it learned to classify a playlist (`Test.csv`, a playlist with 100 songs that may or may not fit well between Steven Wilson songs). Also I'll add the predicted value and probabilites to the `Test` dataset."
    },
    {
      "metadata": {
        "_cell_guid": "3e35da45-238d-43e1-bbc4-9caafd3c9309",
        "_uuid": "2ac08ab894fa4e81eebe061b7fb741eb49f6b6fa",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# classify/predict class of test songs\npredictions = kn.predict(clean_test_data[cols])\ntest_data['predict'] = predictions\n\n# probability that a song is 0/1\ntest_prob = kn.predict_proba(clean_test_data[cols])\nprob0 = [p[0] for p in test_prob]\nprob1 = [p[1] for p in test_prob]\ntest_data['prob0'] = prob0\ntest_data['prob1'] = prob1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b08b2967-a7e3-44ce-a2c6-87009d996b34",
        "_uuid": "350923358972464130907ec96d45ecfd540e884a"
      },
      "cell_type": "markdown",
      "source": "## Results\nLet's check the results. If you want to check them yourself, give [Steven Wilson](https://open.spotify.com/artist/4X42BfuhWCAZ2swiVze9O0)/[Porcupine Tree](https://open.spotify.com/artist/5NXHXK6hOCotCF8lvGM1I0) a listen and then head over to the [Test playlist](https://open.spotify.com/user/jdgs.gt/playlist/6wCTUaDlzdzrqMUzkCd9Zx) and listen to the songs where `prob1` is 1 to check similarities. Or listen to the songs where `prob0` is 1, and you'll see the huge differences of musical style.\n\n **UPDATE**: I added the songs with > 80% probability of being **1**  (similar to Steven Wilson) to [this playlist](https://open.spotify.com/user/jdgs.gt/playlist/0D7EWUrrBuza4H8SuzDqyI). It's just 35 songs long, but the results are really good. "
    },
    {
      "metadata": {
        "_uuid": "b424a11cf244bd06a33b21c988bc97f06ea877f3",
        "collapsed": true,
        "scrolled": true,
        "_kg_hide-output": false,
        "_cell_guid": "17d7272f-aa11-4c22-b5b0-626a45677902",
        "_kg_hide-input": false,
        "trusted": false
      },
      "cell_type": "code",
      "source": "test_data[['name','predict', 'prob0', 'prob1']]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f6b81974-a6c2-4f8b-84e8-b729e23d9ab2",
        "_uuid": "2d2d3b93b899a699b27b01f7bfb2314d52c15b8b"
      },
      "cell_type": "markdown",
      "source": "## Conclusion\nIn my opinion, the algorithm did an excellent job. But in a problem like this, the accuracy is a little subjective, right?"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "name": "python",
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}